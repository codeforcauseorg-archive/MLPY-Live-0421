{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HYj_U8aX3TpV"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0OC9b73p3cah",
    "outputId": "87324b6e-ffda-489d-fe77-2ca0f271d4c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/anuj/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/anuj/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BDfD558r3odk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "vocab = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrVwUXJb3t4-",
    "outputId": "987e9a17-7f04-4bbb-90a3-3c90774ced7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FY9-4RgE4OvF",
    "outputId": "97913237-4bea-4e41-9dfb-f00ddf6532d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "954"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uQncd8eA9qS5"
   },
   "outputs": [],
   "source": [
    "# vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "b8924ASa9vOA"
   },
   "outputs": [],
   "source": [
    "rev = [[value, key] for [key, value] in vocab.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vjDWJJ_J-Bld"
   },
   "outputs": [],
   "source": [
    "rev_vocab = dict(rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PxtHM92l-mxX",
    "outputId": "069470da-b46c-4c9f-8d36-3505751a013a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(list(rev_vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "rEKP4TU8-v9F",
    "outputId": "dd9cf87e-3f41-4826-9fb1-8663c47ab84b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lrjdMSWs-QXT"
   },
   "outputs": [],
   "source": [
    "sent = X_train[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "fEOu3O9F-THq",
    "outputId": "ad3a5638-f224-4c4a-afb1-ffa4b79ea127"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"production and performances in this of classic about the game within and between the in and are a as friends who must through and to that they love each other good humor is a which goes a long way towards the of the material which has been down a bit in its i liked the look of the film and how shots were set up and i thought it didn't too much on of head shots like most other films of the and do very good\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([rev_vocab[idx-3] for idx in sent if idx > 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DvUhCEnm-iQM"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NyjNTRpb_6PI"
   },
   "outputs": [],
   "source": [
    "X_train_mod = pad_sequences(X_train, maxlen=100)\n",
    "X_test_mod = pad_sequences(X_test, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eoLOcwyxAbwx",
    "outputId": "4350904c-2fc7-4d39-a0b8-c86c9db2b45f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1af_Cd2FAfEh"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QDl3ZhyZBWE9",
    "outputId": "a9ed0378-5502-46b2-9f1e-3c055db4108d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bWjhzGcmAzOS"
   },
   "outputs": [],
   "source": [
    "in_layer = Input(shape=(100,))\n",
    "embedding = Embedding(input_dim=1001, output_dim=20)(in_layer)\n",
    "rnn_layer = LSTM(units=100)(embedding)\n",
    "out_layer = Dense(1, activation=\"sigmoid\")(rnn_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "zZPdY9xMBkZ4"
   },
   "outputs": [],
   "source": [
    "model = Model(in_layer, out_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DmXbY9niBnZr",
    "outputId": "b6cd2cb2-1c4c-474a-d4cc-6fd9a1f135f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 100, 20)           20020     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               48400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 68,521\n",
      "Trainable params: 68,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "PoKph4sVBsOI"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZkOTmxI_B1z_",
    "outputId": "caf9dd2f-6a78-4f56-c648-4e9caf15c17b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 52s 2s/step - loss: 0.2421 - accuracy: 0.5888\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 49s 2s/step - loss: 0.1977 - accuracy: 0.7102\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 56s 2s/step - loss: 0.1509 - accuracy: 0.7909\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 56s 2s/step - loss: 0.1311 - accuracy: 0.8181\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 52s 2s/step - loss: 0.1228 - accuracy: 0.8292\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 52s 2s/step - loss: 0.1170 - accuracy: 0.8389\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 53s 2s/step - loss: 0.1155 - accuracy: 0.8421\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 50s 2s/step - loss: 0.1143 - accuracy: 0.8441\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 52s 2s/step - loss: 0.1122 - accuracy: 0.8476\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 53s 2s/step - loss: 0.1104 - accuracy: 0.8526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcbba16af40>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_mod, y_train, epochs=10, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2TZA9KLMB8eF",
    "outputId": "083e3d46-cf77-49ae-f1f1-2754bcffe731"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.12615881860256195, 0.8213599920272827]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_mod, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNVBShefCWvt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "4H8QkLo1DCDB",
    "outputId": "8da1b1ac-1863-4f53-f4b9-4e262a83f069"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"please don't waste your time on this...its very boring. it's like they pre-sell the movie with a good ending of infinity war. its a rip off. trust me you won't believe this. i quite after 30 minutes.\\n\\ni am writing this review to alert people: keep your money and time for something else.\""
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fromimdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V0olO7_cDGaG"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AU7V32dPDlBu",
    "outputId": "09015997-bd6a-47e8-e5d2-a2b7c1693795"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"popular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6TWu5S2DVeG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2dAyRfzEGJT"
   },
   "outputs": [],
   "source": [
    "vocab_words = set([key for key in vocab.keys() if vocab[key] < 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bcd8XkbQEMth"
   },
   "outputs": [],
   "source": [
    "fromimdb = r\"\"\"After Avengers Infinity War, we waited for the Avengers Endgame. We wondered how the story would go on, how our heroes would turn back, what would be the end of Thanos. Many theories related to this have been put forward. Avengers Endgame was undoubtedly the most anticipated film of recent years. Normally, the higher the expectation, the higher the probability of disappointment. But this is not the case for Endgame. Whatever you're expecting, you find much more in the film. This means that the biggest concern about the film has disappeared.\n",
    "\n",
    "On the other hand, another comparison comes up. Is Endgame more successful than Infinity War? We can comfortably say it Avengers Infinity War is just the beginning of the story. Endgame was the finale of the story. So we shouldn't think of these two films as two separate stories. There is only one story divided into two parts.\n",
    "\n",
    "Avengers Endgame is, above all, a great homage to the ten-year history of the Marvel Cinematic Universe. The story highlights the original Avengers team. Iron Man, Captain America, Thor, Hulk, Black Widow and Hawkeye are at the center of events. No character comes in front of them. Of course there are many characters that play an important role in the story outside the original Avengers team. Everyone's concern was that Captain Marvel, who was included in the Marvel world, overshadowed other heroes. We can say that this certainly did not happen. What is important in this struggle is not how strong you are, but how good you are. This comes to the fore in all areas. It gives good message about being a hero and a family..\"\"\".lower()\n",
    "words = word_tokenize(fromimdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-pRP69oDbmp"
   },
   "outputs": [],
   "source": [
    "out = [vocab[word]+3 for word in words if word in vocab_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBk10Cy3EYyj"
   },
   "outputs": [],
   "source": [
    "X = pad_sequences([out], maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9lBX0ye_Eggh",
    "outputId": "c948844b-4ec4-427f-a23d-158b5066d252"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 83, 107, 531,   9, 752,  32,   6,  87,   8,   4, 479,   7,   4,\n",
       "          4,  65,   4, 204, 768, 132, 938, 328,   5,  26,  33,   4,   7,\n",
       "        687,  57, 109, 266,  11,   7,  98,   7, 265,  50,  26, 111, 105,\n",
       "         15, 297,  35, 674, 217,  11,   4,  65,   4, 204, 768, 316,  16,\n",
       "         15,  37,  16,  11,   4, 182,  85,  75,  70, 135,  15,  14, 434,\n",
       "        122,  24, 593,  51,   9, 674,  11,  14,   9,  24,  89, 565,  25,\n",
       "         26,  21,  89,  52,  25,  26,  14, 266,   8,   4,  11,  32,  12,\n",
       "        408,  52, 749,  44, 112,   6, 632,   5,   6]], dtype=int32)"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKwQvXXWE8wZ",
    "outputId": "f823fccb-67d8-47db-97e9-55b9925038bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9423405]], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59u0y5MCE_zv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled38.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
